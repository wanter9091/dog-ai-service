'''
    ì„œë¹„ìŠ¤ ì„¤ëª…
        - ë‹¨ê¸°ê¸°ì–µ ì‚¬ìš©(ëŒ€í™” ë‚´ìš© ë©”ëª¨ë¦¬) -> GPT ì‘ë‹µ ì²˜ë¦¬ ê°€ëŠ¥í•˜ê²Œ êµ¬ì„±
'''
# ëª¨ë“ˆê°€ì ¸ì˜¤ê¸°
# ui
import streamlit as st
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
import os
# ë­ì²´ì¸ + openai ê´€ë ¨ ë¡œë“œ
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
# íˆìŠ¤í† ë¦¬- ë‹¨ê¸°ê¸°ì–µ ì¬í˜„ - ëŒ€í™” ë‚´ìš© ìœ ì§€
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
# ë‹µë³€ì„ êµ¬ì„±í•˜ëŠ” ê³¼ì •ì„ ì½œë°±í•¨ìˆ˜ë¡œ ê³„ì† ì œê³µë°›ì•„ì„œ -> í™”ë©´ìƒì— ì¸í„°ë ‰í‹°ë¸Œí•œ ë³€í™”ë¥¼ ì—°ì¶œ
from langchain_community.callbacks import StreamlitCallbackHandler
# ë­ì²´ì¸ ì—ì´ì „íŠ¸
# AgentExecutor : ì—ì´ì „íŠ¸, íˆ´, ë©”ëª¨ë¦¬ ëª¨ë‘ ê²°í•©
# load_tools : ìœ„í‚¤í”¼ë””ì•„, ê²€ìƒ‰ì—”ë“±ë“± ì—°ê²°
# create_openai_tools_agent : openaië¥¼ ìœ„í•œ ì—ì´ì „íŠ¸ (ë©”ëª¨ë¦¬, íˆ´, ëª¨ë¸)
from langchain.agents import AgentExecutor, load_tools, create_openai_tools_agent
# ëŒ€í™” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ gptê°€ ì‘ë‹µì„ í• ìˆ˜ ìˆê²Œ ì œê³µ
from langchain.memory import ConversationBufferMemory
# í—ˆë¸Œ
from langchain import hub

# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ -> ë°ì´í„° íšë“
load_dotenv()
# í™•ì¸
# print(os.environ['OPENAI_API_KEY'])
# print(os.environ['OPENAI_API_MODEL'])
# print(os.environ['OPENAI_API_TEMPERATURE'])

# ì„¤ì • : 1. openaië§Œ ì‚¬ìš©, 2. ë­ì²´ì¸ ì—ì´ì „íŠ¸ë¥¼ ì´ìš© ê²€ìƒ‰ì¦ê°•, 3. ë”ë¯¸
ai_res_type = 2


# ì „ì—­ ë³€ìˆ˜ íŒŒíŠ¸


def init_chat():
    '''
        ì±„íŒ… ì´ˆê¸°í™” - UI, ì±„íŒ… ë©”ì„¸ì§€ íˆìŠ¤í† ë¦¬ ì²˜ë¦¬, í”„ëŸ¼í”„íŠ¸ì²˜ë¦¬
    '''
    # ui
    st.title('LLM,ë­ì²´ì¸,streamlitê¸°ë°˜ ì„œë¹„ìŠ¤')
    # ì±„íŒ… ì…ë ¥ì°½
    prompt = st.chat_input('ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?')
    print(prompt)
    # íˆìŠ¤í† ë¦¬ ì²˜ë¦¬ -> ê¸°ì–µ -> ë­ì²´ì¸(ë‹¨ê¸°ê¸°ì–µ) or ë°±í„°ë””ë¹„(ì¥ê¸°ê¸°ì–µ)
    history = StreamlitChatMessageHistory()
    # ëŒ€í™” ë‚´ì—­ ì¶œë ¥ -> ë°˜ë³µ
    for message in history.messages:
        # ë©”ì„¸ì§€ ìœ í˜•( ì‚¬ìš©ì í˜¹ì€ ai(ì–´ì‹œìŠ¤í„´ìŠ¤) ) + ë©”ì„¸ì§€ í˜•íƒœ
        st.chat_message(message.type).write(message.content)

    # ì±„íŒ…(ë´‡) ì°½ì— ë©”ì„¸ì§€ ì„¸íŒ…
    # promptê°€ ì¡´ì¬í•˜ë©´
    if prompt:  # ë­”ê°€ë¥¼ ì…ë ¥í–ˆë‹¤
        with st.chat_message('user'):  # ì¼ë°˜ ìœ ì €ì˜ ì•„ì´ì½˜ìœ¼ë¡œ ì±„íŒ…ì°½ì— ë©”ì„¸ì§€ ì„¸íŒ…ë˜ëŠ” í‘œì‹
            # íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ë©”ì„¸ì§€(í”„ëŸ¼í”„íŠ¸) ì €ì¥
            history.add_user_message(prompt)
            # ì‚¬ìš©ì ë©”ì„¸ì§€ë¥¼ í‘œê¸°
            st.markdown(prompt)

        with st.chat_message('assistant'):
            # aiì˜ ì‘ë‹µ ; openai | openai + ìœ„í‚¤í”¼ë””ì•„ +  ê¸°íƒ€ ê²€ìƒ‰ì—”ì§„ë“± ì¦ê°•í•˜ì—¬
            if ai_res_type == 2:    # openai + ìœ„í‚¤í”¼ë””ì•„ +  ê¸°íƒ€ ê²€ìƒ‰ì—”ì§„ë“± ì¦ê°•í•˜ì—¬ ë‹µë³€
                # 1. ì½œë°± êµ¬ì„±
                cb = StreamlitCallbackHandler(st.container())
                # 2. ë­ì²´ì¸ ì—ì´ì „íŠ¸ êµ¬ì„± -> íˆìŠ¤í† ë¦¬ ì „ë‹¬ -> ëŒ€í™” ë‚´ìš©ì„ ì „ë‹¬(ê¸°ì–µ)
                agent_chain = init_agent_chain(history)
                # 3. ì—ì´ì „íŠ¸ ì´ìš©í•˜ì—¬ llm ì§ˆì˜
                res = agent_chain.invoke(
                    {"input": prompt},   # ì‚¬ìš©ìì˜ ì§ˆì˜
                    {"callbacks": [cb]}  # ì‘ë‹µ ì‘ì„±ì¤‘ì— ë¡œê·¸->í™”ë©´ í‘œê¸°ë“±ë“± ì—°ì¶œ
                )
                # 4. ì‘ë‹µ -> íˆìŠ¤í† ë¦¬ ë“±ë¡
                history.add_ai_message(res['output'])
                # 5. ê²°ê³¼ ì¶œë ¥
                st.markdown(res['output'])
                pass
            elif ai_res_type == 1:  # openaië¡œë§Œ ë‹µë³€
                # 1. GPT ì²˜ë¦¬í• ìˆ˜ ìˆëŠ” ChatOpenAI ê°ì²´ ìƒì„±
                llm = ChatOpenAI(
                    model_name=os.environ['OPENAI_API_MODEL'],
                    temperature=os.environ['OPENAI_API_TEMPERATURE']
                )
                # 2. í”„ëŸ¼í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (ì„œë¹„ìŠ¤ ì»¨ì…‰ ë¶€ì—¬ ê°€ëŠ¥) ì—¬ê¸°ì„œëŠ” íœ´ë¨¼ë©”ì„¸ì§€êµ¬ì„±
                msg = [HumanMessage(content=prompt)]
                # 4. GPT ìš”ì²­ -> ì½œë°± ì²˜ë¦¬ í•¨ìˆ˜ëŠ” ë‹¤ë¦„(ì—ì´ì „íŠ¸ì—ì„œ ì²˜ë¦¬)
                res = llm.invoke(msg)
                # 5. ì‘ë‹µ ë„ì°©, íˆìŠ¤í† ë¦¬ì— ë‹´ê¸°
                print(res.content)
                history.add_ai_message(res.content)
                # 6. í™”ë©´ ì„¸íŒ…
                st.markdown(res.content)
                pass
            else:  # ë”ë¯¸ ì‘ë‹µ
                st.markdown('ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š')
    pass

# ë­ì²´ì¸-ì—ì´ì „íŠ¸ ì´ˆê¸°í™”


def init_agent_chain(history):
    '''
        - ì—¬ëŸ¬ ê°œì˜ ì‘ì—…ì„ ì—°ì†ì ìœ¼ë¡œ ì—°ê²°(chain)ë˜ì–´ì„œ ì§„í–‰ë˜ê²Œ êµ¬ì„± -> ì£¼ì²´:agent
        - parameters
            - history : ëŒ€í™” ë‚´ì—­
        - returns
            - AgentExecutor ê°ì²´        
    '''
    # 1. GPT ìƒì„±
    llm = ChatOpenAI(
        model_name=os.environ['OPENAI_API_MODEL'],
        temperature=os.environ['OPENAI_API_TEMPERATURE']
    )
    # 2. íˆ´ ìƒì„± (hubë¥¼ í†µí•´ì„œ ì™¸ë¶€ ìì› í™œìš© -> ê²€ìƒ‰ì¦ê°•, ë°ì´í„° ì¶”ê°€ ë“±ë“±....)
    tools = load_tools([  # "ddg-search",
        "wikipedia"])
    # 3. ì™¸ë¶€ ìì›ì„ ì‚¬ìš©í•˜ë£¨ ìˆëŠ” í—ˆë¸Œ êµ¬ì„±
    hub_tool = hub.pull('hwchase17/openai-tools-agent')
    # 4. (*)ë©”ëª¨ë¦¬ êµ¬ì„± (ì±„íŒ… ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí• ìˆ˜ ìˆê²Œ êµ¬ì„±)
    memory = ConversationBufferMemory(
        chat_memory=history,
        # ì´ ëŒ€í™”ì— ëŒ€í•´ íŠ¹ì •í• ìˆ˜ ìˆëŠ” í‚¤, í˜„ì¬ëŠ” ê³ ì •, ì°¨í›„ ëŒ€í™”ë³„ë¡œ ë‹¤ë¥´ê²Œ êµ¬ì„± ê°€ëŠ¥í•¨
        # chatgpt ì—ì„œ ì™¼ìª½ ë©”ë‰´ì— ëŒ€í™”ì°½ ë³„ë¡œ ê´€ë¦¬ë˜ëŠ” í•­ëª© ì²´í¬
        memory_key='my_first_chat',
        return_messages=True
    )
    # 5. ì—ì´ì „íŠ¸ êµ¬ì„± (ëª¨ë¸, íˆ´, í—ˆë¸Œ) : openai + ì™¸ë¶€ìì›
    agent = create_openai_tools_agent(llm, tools, hub_tool)
    # 6. (*)ì—ì´ì „íŠ¸ ì‹¤í–‰ì êµ¬ì„± (ì—ì´ì „íŠ¸, íˆ´, ë©”ëª¨ë¦¬) => ì—ì´ì „íŠ¸ ì²´ì¸
    return AgentExecutor(agent=agent, tools=tools, memory=memory)


def main():
    '''
        ë©”ì¸ í•¨ìˆ˜ - í”„ë¡œê·¸ë¨ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸(ì§„ì…ë¡œ)
    '''
    init_chat()
    pass


# í”„ë¡œê·¸ë¨ ê°€ë™
if __name__ == '__main__':
    main()
